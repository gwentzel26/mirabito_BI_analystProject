{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5601fafb-9c83-4c4e-a600-0e41ae5127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e8aba0-001d-4a4c-af5e-947039936152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"/Users/gavinwentzel/Desktop/Grad School/Mirabito Project/Mirabito_Documentation/Final_Data_Long.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c752b820-7f21-4e42-b7ca-f88a4f779606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to Desktop as: basketAnalysis.csv\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"Loyalty_Program\"])\n",
    "\n",
    "# FP-Growth function with top 20 and readable formatting\n",
    "def run_fpgrowth_on_subset(subset_df, min_support=0.01):\n",
    "    grouped = subset_df.groupby('Transaction_ID')['Item_Category'].apply(list).tolist()\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(grouped).transform(grouped)\n",
    "    basket_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    frequent_itemsets = fpgrowth(basket_df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "    rules = rules.sort_values(by=\"lift\", ascending=False).head(20)\n",
    "\n",
    "    # Convert frozenset to readable strings\n",
    "    rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "    rules[\"Rule\"] = rules[\"antecedents\"] + \" → \" + rules[\"consequents\"]\n",
    "    return rules\n",
    "\n",
    "# Define labeled segments\n",
    "all_rules = []\n",
    "\n",
    "segments = {\n",
    "    \"Mirabito Loyalty\": df[df['Loyalty_Program'] == 'Mirabito Loyalty'],\n",
    "    \"Alt ID Loyalty\": df[df['Loyalty_Program'] == 'Mirabito Alt ID'],\n",
    "    \"Rewards and Payment\": df[df['Loyalty_Program'] == 'Rewards and Payment'],\n",
    "    \"High CLV\": df[df['CLV_Tier'] == 'High'],\n",
    "    \"Fuel Transactions\": df[df['Transaction_ID'].isin(df[df['Item_Category'] == 'FUEL']['Transaction_ID'].unique()) &\n",
    "                            (df['Item_Category'] != 'FUEL')]\n",
    "}\n",
    "\n",
    "# Generate rules for each segment\n",
    "for label, subset in segments.items():\n",
    "    rules = run_fpgrowth_on_subset(subset)\n",
    "    rules[\"Source\"] = label\n",
    "    all_rules.append(rules)\n",
    "\n",
    "# Combine and export\n",
    "combined_rules_df = pd.concat(all_rules, ignore_index=True)\n",
    "combined_rules_df.to_csv(\"/Users/gavinwentzel/Desktop/basketAnalysis.csv\", index=False)\n",
    "\n",
    "print(\"Exported to Desktop as: basketAnalysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c704c0c0-ba7a-408f-ad63-f320d98de2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Transaction_ID  Customer_PK Loyalty_Program   ItemID  Quantity  \\\n",
      "1504          2489764       607834    Weis Loyalty  3275984      1.00   \n",
      "1505          2489764       607834    Weis Loyalty  3273458      1.00   \n",
      "25119         1900267       759975    Weis Loyalty       -1     11.02   \n",
      "25120         1900267       759975    Weis Loyalty       -1     11.02   \n",
      "25121         1900267       759975    Weis Loyalty       -1      1.00   \n",
      "\n",
      "          Transaction_Date Transaction_Time      CLV CLV_Tier  \\\n",
      "1504   2025-05-28 00:00:00         11:00:00    8.000      Low   \n",
      "1505   2025-05-28 00:00:00         11:00:00    8.000      Low   \n",
      "25119  2025-05-28 00:00:00         16:30:00  973.184     High   \n",
      "25120  2025-05-28 00:00:00         16:30:00  973.184     High   \n",
      "25121  2025-05-28 00:00:00         16:30:00  973.184     High   \n",
      "\n",
      "           Item_Category  Unit_Price  Item_Revenue  \n",
      "1504   Cig Promotions(R)        0.25          0.25  \n",
      "1505          CIGARETTES       15.69         15.69  \n",
      "25119               FUEL        3.50         38.57  \n",
      "25120               FUEL        3.50         38.57  \n",
      "25121               FUEL        3.50          3.50  \n"
     ]
    }
   ],
   "source": [
    "# 3 Questions CSVs\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"/Users/gavinwentzel/Desktop/Final_Data_Long.csv\")\n",
    "\n",
    "# 1. Average fuel quantity by loyalty group\n",
    "avg_fuel_by_loyalty = df[df[\"Item_Category\"] == \"FUEL\"].groupby(\"Loyalty_Program\")[\"Quantity\"].mean().reset_index()\n",
    "avg_fuel_by_loyalty.columns = [\"Loyalty_Program\", \"Average_Gallons\"]\n",
    "avg_fuel_by_loyalty.to_csv(\"avg_fuel_by_loyalty.csv\", index=False)\n",
    "\n",
    "# 2. Co-purchased item pairs\n",
    "grouped_tx = df.groupby(\"Transaction_ID\")[\"Item_Category\"].apply(list)\n",
    "pair_counts = {}\n",
    "\n",
    "for items in grouped_tx:\n",
    "    unique_items = list(set(items))\n",
    "    for pair in itertools.combinations(sorted(unique_items), 2):\n",
    "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
    "\n",
    "pair_df = pd.DataFrame([\n",
    "    {\"Item_A\": k[0], \"Item_B\": k[1], \"Count\": v} for k, v in pair_counts.items()\n",
    "])\n",
    "pair_df.to_csv(\"item_pair_counts.csv\", index=False)\n",
    "\n",
    "# 3. Transaction-level basket table\n",
    "basket_table = df.groupby(['Transaction_ID', 'Customer_PK', 'Loyalty_Program', 'CLV_Tier'])['Item_Category'] \\\n",
    "    .apply(lambda x: ', '.join(sorted(set(x)))).reset_index()\n",
    "basket_table.columns = ['Transaction_ID', 'Customer_PK', 'Loyalty_Program', 'CLV_Tier', 'Basket_Items']\n",
    "basket_table.to_csv(\"transaction_baskets.csv\", index=False)\n",
    "\n",
    "print(\"CSVs exported: avg_fuel_by_loyalty.csv, item_pair_counts.csv, transaction_baskets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38a47d-5515-4e64-8f38-0d1c315703e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLV frequent bundles\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"/Users/gavinwentzel/Desktop/Final_Data_Long.csv\")\n",
    "\n",
    "# Filter for rows with a valid CLV Tier\n",
    "clv_grouped_df = df[df[\"CLV_Tier\"].notna()]\n",
    "\n",
    "# Function to compute pair metrics per CLV_Tier\n",
    "def compute_grouped_pair_metrics(filtered_df, group_label):\n",
    "    results = []\n",
    "    for group_val, group_df in filtered_df.groupby(group_label):\n",
    "        total_tx = group_df[\"Transaction_ID\"].nunique()\n",
    "        tx_series = group_df.groupby(\"Transaction_ID\")[\"Item_Category\"].apply(set)\n",
    "\n",
    "        item_ct = Counter()\n",
    "        pair_ct = Counter()\n",
    "        for items in tx_series:\n",
    "            item_ct.update(items)\n",
    "            for pair in itertools.combinations(sorted(items), 2):\n",
    "                pair_ct[pair] += 1\n",
    "\n",
    "        for (a, b), count in pair_ct.items():\n",
    "            support = count / total_tx\n",
    "            confidence_a_to_b = count / item_ct[a]\n",
    "            confidence_b_to_a = count / item_ct[b]\n",
    "            lift_a_to_b = confidence_a_to_b / (item_ct[b] / total_tx)\n",
    "            lift_b_to_a = confidence_b_to_a / (item_ct[a] / total_tx)\n",
    "            results.append({\n",
    "                group_label: group_val,\n",
    "                \"Item_A\": a,\n",
    "                \"Item_B\": b,\n",
    "                \"Pair_Count\": count,\n",
    "                \"Support\": round(support, 4),\n",
    "                \"Confidence_A_to_B\": round(confidence_a_to_b, 4),\n",
    "                \"Confidence_B_to_A\": round(confidence_b_to_a, 4),\n",
    "                \"Lift_A_to_B\": round(lift_a_to_b, 2),\n",
    "                \"Lift_B_to_A\": round(lift_b_to_a, 2),\n",
    "                \"Item_Pair\": f\"{a} → {b}\"\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Compute all pair metrics for CLV_Tier groups\n",
    "pair_metrics_by_clv = compute_grouped_pair_metrics(clv_grouped_df, \"CLV_Tier\")\n",
    "\n",
    "# Rank by support within each CLV_Tier and filter top 5\n",
    "pair_metrics_by_clv[\"Support_Rank\"] = pair_metrics_by_clv.groupby(\"CLV_Tier\")[\"Support\"].rank(method=\"first\", ascending=False)\n",
    "top_clv_by_support = pair_metrics_by_clv[pair_metrics_by_clv[\"Support_Rank\"] <= 5].sort_values([\"CLV_Tier\", \"Support_Rank\"])\n",
    "\n",
    "# Export to CSV\n",
    "top_clv_by_support.to_csv(\"frequent_bundles_CLV.csv\", index=False)\n",
    "\n",
    "print(\"File saved: frequent_bundles_CLV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c24329d-9e10-4fdd-8b72-eb26f4a8d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported to Desktop as: basket_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# Group items by transaction\n",
    "transactions = df.groupby(\"Transaction_ID\")[\"Item_Category\"].apply(list).tolist()\n",
    "\n",
    "# One-hot encode items\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "basket_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Run FP-Growth\n",
    "frequent_itemsets = fpgrowth(basket_df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Clean up the rules for readability\n",
    "rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: \", \".join(sorted(x)))\n",
    "rules[\"Rule\"] = rules[\"antecedents\"] + \" → \" + rules[\"consequents\"]\n",
    "\n",
    "# Sort and keep top 100 by lift\n",
    "rules = rules.sort_values(by=\"lift\", ascending=False).head(100)\n",
    "\n",
    "# Export to Desktop\n",
    "rules.to_csv(\"/Users/gavinwentzel/Desktop/basket_analysis.csv\", index=False)\n",
    "\n",
    "print(\"Exported to Desktop as: basket_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b952b1d-1225-4a37-9a1a-598f21c56740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
